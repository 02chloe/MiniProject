{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This part is trying to build an A2C model for trading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "import preprocessing_env_custom_with_vol \n",
    "import preprocessing_adding_technical_indicator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers as kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor nn\n",
    "class Actor(object):\n",
    "\n",
    "    def __init__(self, state_dim =6, action_dim =3, lr=0.001):\n",
    "        \n",
    "\n",
    "        input_layer = tl.layers.Input([None, state_dim])\n",
    "        layer = tl.layers.Dense(n_units=12, act=tf.nn.relu6)(input_layer)\n",
    "        layer = tl.layers.Dense(n_units=action_dim)(layer)\n",
    "#         input_layer =kl.Input(shape=state_dim)\n",
    "#         layer1 = kl.Dense(12,activation ='elu')(input_layer)\n",
    "#         layer2 = kl.Dense(3)(layer1)\n",
    "\n",
    "        self.model = tl.models.Model(inputs=input_layer, outputs=layer)  # define the model in and out\n",
    "#         self.model = keras.Model(inputs = [input_layer],outputs =[layer2])\n",
    "        self.model.train()\n",
    "        self.optimizer = tf.optimizers.Adam(lr)\n",
    "\n",
    "    def learn(self, state, action, td_error):  # update weights according to cross_entropy\n",
    "        with tf.GradientTape() as tape:\n",
    "            _logits = self.model(np.array([state]))\n",
    "            _exp_v = tl.rein.cross_entropy_reward_loss(\n",
    "                logits=_logits, actions=[action], rewards=td_error)\n",
    "        grad = tape.gradient(_exp_v, self.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grad, self.model.trainable_weights))\n",
    "\n",
    "    def get_action(self, state):  # option : greedy para to get the max prob\n",
    "        _logits = self.model(np.array([state]))\n",
    "        _prob = tf.nn.softmax(_logits).numpy()\n",
    "        return tl.rein.choice_action_by_probs(_prob.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# critic nn\n",
    "class Critic(object):\n",
    "\n",
    "    def __init__(self, state_dim =6, lr=0.01):\n",
    "        input_layer = tl.layers.Input([None, state_dim])\n",
    "        layer = tl.layers.Dense(n_units=12, act=tf.nn.relu)(input_layer) # 12  is the twice of the input dimension\n",
    "        layer = tl.layers.Dense(n_units=1, act=None)(layer)  # output one\n",
    "\n",
    "        self.model = tl.models.Model(inputs=input_layer, outputs=layer)\n",
    "        self.model.train()\n",
    "        self.optimizer = tf.optimizers.Adam(lr)\n",
    "\n",
    "    def learn(self, state, reward, state_, done):\n",
    "        d = 0 if done else 1\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            v = self.model(np.array([state]))\n",
    "            v_ = self.model(np.array([state_]))  # new state  value\n",
    "            td_error = reward + d * gamma * v_ - v\n",
    "            loss = tf.square(td_error)  # MSE\n",
    "        grads = tape.gradient(loss, self.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "        return td_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000e+03  0.00000e+00  0.00000e+00  2.62000e+02  0.00000e+00\n",
      " -6.66667e+01  4.69697e+01  3.16346e+05]\n"
     ]
    }
   ],
   "source": [
    "data = preprocessing_adding_technical_indicator.add_technical_indicator()\n",
    "env = preprocessing_env_custom_with_vol .StockEnv(data)\n",
    "LR_A = 0.001  # learning rate for actor\n",
    "LR_C = 0.01  # learning rate for critic\n",
    "decay = 0.005 # learning rate decay\n",
    "gamma = 0.95 # discount factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Input  _inputlayer_1: [None, 6]\n",
      "[TL] Dense  dense_1: 12 relu6\n",
      "[TL] Dense  dense_2: 3 No Activation\n",
      "[TL] Input  _inputlayer_2: [None, 6]\n",
      "[TL] Dense  dense_3: 12 relu\n",
      "[TL] Dense  dense_4: 1 No Activation\n"
     ]
    }
   ],
   "source": [
    "actor = Actor(env.observation_space.shape[0], env.action_space.n, lr=LR_A)\n",
    "critic = Critic(env.observation_space.shape[0], lr=LR_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trade_time_unit(env, obs):  #  using greedy policy\n",
    "#     action = actor.get_action(obs) # get the action\n",
    "#     print(action)\n",
    "#     next_state, reward, done, info = env.step(action)\n",
    "#     return next_state, reward, done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_episode():\n",
    "    env.reset()\n",
    "    state = env.reset().astype(np.float32)\n",
    "    reward_total = 0\n",
    "    for step in range(2100):\n",
    "        action = actor.get_action(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        reward_total = reward_total + reward\n",
    "        next_state = next_state.astype(np.float32)\n",
    "        td_error = critic.learn(state,reward,next_state,done)\n",
    "        actor.learn(state,action,td_error)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(state)\n",
    "            break\n",
    "    print(\"For this episode,reward total:{}\".format(reward_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1000,\n",
       " 1003.8168,\n",
       " 1000.0,\n",
       " 977.0992,\n",
       " 961.8321,\n",
       " 1000.0,\n",
       " 980.916,\n",
       " 996.1832,\n",
       " 1000.0,\n",
       " 980.916,\n",
       " 965.6489,\n",
       " 961.8321,\n",
       " 965.6489,\n",
       " 984.7328,\n",
       " 954.1985,\n",
       " 961.8321,\n",
       " 946.5649,\n",
       " 912.2137,\n",
       " 912.2137,\n",
       " 923.6641,\n",
       " 927.4809,\n",
       " 923.6641,\n",
       " 935.1145,\n",
       " 923.6641,\n",
       " 923.6641,\n",
       " 919.8473,\n",
       " 927.4809,\n",
       " 885.4962,\n",
       " 904.5802,\n",
       " 942.7481,\n",
       " 927.4809,\n",
       " 931.2977,\n",
       " 893.1298,\n",
       " 923.6641,\n",
       " 938.9313,\n",
       " 942.7481,\n",
       " 931.2977,\n",
       " 923.6641,\n",
       " 904.5802,\n",
       " 950.3817,\n",
       " 935.1145,\n",
       " 942.7481,\n",
       " 919.8473,\n",
       " 950.3817,\n",
       " 923.6641,\n",
       " 935.1145,\n",
       " 935.1145,\n",
       " 931.2977,\n",
       " 927.4809,\n",
       " 923.6641,\n",
       " 919.8473,\n",
       " 927.4809,\n",
       " 919.8473,\n",
       " 916.0305,\n",
       " 935.1145,\n",
       " 935.1145,\n",
       " 942.7481,\n",
       " 938.9313,\n",
       " 954.1985,\n",
       " 965.6489,\n",
       " 969.4656,\n",
       " 919.8473,\n",
       " 931.2977,\n",
       " 942.7481,\n",
       " 942.7481,\n",
       " 931.2977,\n",
       " 908.3969,\n",
       " 900.7634,\n",
       " 896.9466,\n",
       " 950.3817,\n",
       " 946.5649,\n",
       " 931.2977,\n",
       " 946.5649,\n",
       " 912.2137,\n",
       " 923.6641,\n",
       " 923.6641,\n",
       " 912.2137,\n",
       " 935.1145,\n",
       " 904.5802,\n",
       " 900.7634,\n",
       " 912.2137,\n",
       " 900.7634,\n",
       " 896.9466,\n",
       " 900.7634,\n",
       " 923.6641,\n",
       " 931.2977,\n",
       " 916.0305,\n",
       " 908.3969,\n",
       " 931.2977,\n",
       " 946.5649,\n",
       " 965.6489,\n",
       " 942.7481,\n",
       " 965.6489,\n",
       " 938.9313,\n",
       " 919.8473,\n",
       " 927.4809,\n",
       " 912.2137,\n",
       " 938.9313,\n",
       " 969.4656,\n",
       " 931.2977,\n",
       " 927.4809,\n",
       " 938.9313,\n",
       " 935.1145,\n",
       " 935.1145,\n",
       " 969.4656,\n",
       " 958.0153,\n",
       " 969.4656,\n",
       " 931.2977,\n",
       " 904.5802,\n",
       " 931.2977,\n",
       " 935.1145,\n",
       " 950.3817,\n",
       " 935.1145,\n",
       " 958.0153,\n",
       " 958.0153,\n",
       " 961.8321,\n",
       " 969.4656,\n",
       " 946.5649,\n",
       " 927.4809,\n",
       " 958.0153,\n",
       " 977.0992,\n",
       " 954.1985,\n",
       " 965.6489,\n",
       " 938.9313,\n",
       " 950.3817,\n",
       " 973.2824,\n",
       " 1007.6336,\n",
       " 977.0992,\n",
       " 961.8321,\n",
       " 969.4656,\n",
       " 958.0153,\n",
       " 958.0153,\n",
       " 1000.0,\n",
       " 1034.3511,\n",
       " 1038.1679,\n",
       " 1045.8015,\n",
       " 1015.2672,\n",
       " 1034.3511,\n",
       " 1057.2519,\n",
       " 1072.5191,\n",
       " 1061.0687,\n",
       " 1076.3359,\n",
       " 1099.2366,\n",
       " 1072.5191,\n",
       " 1083.9695,\n",
       " 1095.4198,\n",
       " 1110.687,\n",
       " 1122.1374,\n",
       " 1099.2366,\n",
       " 1106.8702,\n",
       " 1141.2214,\n",
       " 1133.5878,\n",
       " 1080.1527,\n",
       " 1091.6031,\n",
       " 1125.9542,\n",
       " 1118.3206,\n",
       " 1106.8702,\n",
       " 1106.8702,\n",
       " 1103.0534,\n",
       " 1106.8702,\n",
       " 1118.3206,\n",
       " 1175.5725,\n",
       " 1114.5038,\n",
       " 1125.9542,\n",
       " 1137.4046,\n",
       " 1106.8702,\n",
       " 1129.771,\n",
       " 1103.0534,\n",
       " 1091.6031,\n",
       " 1064.8855,\n",
       " 1068.7023,\n",
       " 1064.8855,\n",
       " 1083.9695,\n",
       " 1053.4351,\n",
       " 1053.4351,\n",
       " 1072.5191,\n",
       " 1064.8855,\n",
       " 1087.7863,\n",
       " 1049.6183,\n",
       " 1053.4351,\n",
       " 1034.3511,\n",
       " 1045.8015,\n",
       " 1030.5344,\n",
       " 1072.5191,\n",
       " 1045.8015,\n",
       " 1045.8015,\n",
       " 1045.8015,\n",
       " 1045.8015,\n",
       " 1041.9847,\n",
       " 1045.8015,\n",
       " 1034.3511,\n",
       " 1041.9847,\n",
       " 1057.2519,\n",
       " 1053.4351,\n",
       " 1053.4351,\n",
       " 1041.9847,\n",
       " 1041.9847,\n",
       " 1045.8015,\n",
       " 1022.9008,\n",
       " 1057.2519,\n",
       " 1034.3511,\n",
       " 1030.5344,\n",
       " 1049.6183,\n",
       " 1003.8168,\n",
       " 1011.4504,\n",
       " 1007.6336,\n",
       " 1019.084,\n",
       " 1011.4504,\n",
       " 1000.0,\n",
       " 988.5496,\n",
       " 1007.6336,\n",
       " 1026.7176,\n",
       " 1015.2672,\n",
       " 988.5496,\n",
       " 1015.2672,\n",
       " 1019.084,\n",
       " 1007.6336,\n",
       " 980.916,\n",
       " 1000.0,\n",
       " 1015.2672,\n",
       " 1026.7176,\n",
       " 1034.3511,\n",
       " 1011.4504,\n",
       " 988.5496,\n",
       " 988.5496,\n",
       " 980.916,\n",
       " 1003.8168,\n",
       " 992.3664,\n",
       " 984.7328,\n",
       " 1019.084,\n",
       " 1003.8168,\n",
       " 1000.0,\n",
       " 1038.1679,\n",
       " 1003.8168,\n",
       " 1011.4504,\n",
       " 1011.4504,\n",
       " 1000.0,\n",
       " 980.916,\n",
       " 954.1985,\n",
       " 984.7328,\n",
       " 965.6489,\n",
       " 988.5496,\n",
       " 973.2824,\n",
       " 973.2824,\n",
       " 973.2824,\n",
       " 992.3664,\n",
       " 992.3664,\n",
       " 958.0153,\n",
       " 973.2824,\n",
       " 988.5496,\n",
       " 977.0992,\n",
       " 965.6489,\n",
       " 942.7481,\n",
       " 969.4656,\n",
       " 923.6641,\n",
       " 931.2977,\n",
       " 958.0153,\n",
       " 931.2977,\n",
       " 935.1145,\n",
       " 927.4809,\n",
       " 931.2977,\n",
       " 912.2137,\n",
       " 923.6641,\n",
       " 935.1145,\n",
       " 919.8473,\n",
       " 935.1145,\n",
       " 927.4809,\n",
       " 908.3969,\n",
       " 912.2137,\n",
       " 927.4809,\n",
       " 885.4962,\n",
       " 889.313,\n",
       " 919.8473,\n",
       " 900.7634,\n",
       " 916.0305,\n",
       " 927.4809,\n",
       " 874.0458,\n",
       " 874.0458,\n",
       " 877.8626,\n",
       " 858.7786,\n",
       " 847.3282,\n",
       " 877.8626,\n",
       " 858.7786,\n",
       " 862.5954,\n",
       " 877.8626,\n",
       " 889.313,\n",
       " 854.9618,\n",
       " 851.145,\n",
       " 858.7786,\n",
       " 858.7786,\n",
       " 832.0611,\n",
       " 832.0611,\n",
       " 858.7786,\n",
       " 824.4275,\n",
       " 839.6947,\n",
       " 832.0611,\n",
       " 828.2443000000001,\n",
       " 820.6107,\n",
       " 851.145,\n",
       " 797.7099000000001,\n",
       " 812.9771000000001,\n",
       " 809.1603,\n",
       " 809.1603,\n",
       " 805.3435,\n",
       " 809.1603,\n",
       " 801.5267,\n",
       " 832.0611,\n",
       " 809.1603,\n",
       " 820.6107,\n",
       " 816.7939,\n",
       " 820.6107,\n",
       " 824.4275,\n",
       " 797.7099000000001,\n",
       " 824.4275,\n",
       " 793.8931,\n",
       " 820.6107,\n",
       " 843.5115000000001,\n",
       " 862.5954,\n",
       " 843.5115000000001,\n",
       " 832.0611,\n",
       " 824.4275,\n",
       " 847.3282,\n",
       " 858.7786,\n",
       " 816.7939,\n",
       " 824.4275,\n",
       " 828.2443000000001,\n",
       " 812.9771000000001,\n",
       " 839.6947,\n",
       " 832.0611,\n",
       " 812.9771000000001,\n",
       " 812.9771000000001,\n",
       " 805.3435,\n",
       " 801.5267,\n",
       " 816.7939,\n",
       " 812.9771000000001,\n",
       " 793.8931,\n",
       " 816.7939,\n",
       " 782.4427000000001,\n",
       " 770.9924,\n",
       " 805.3435,\n",
       " 782.4427000000001,\n",
       " 778.626,\n",
       " 774.8092,\n",
       " 786.2595,\n",
       " 767.1756,\n",
       " 767.1756,\n",
       " 778.626,\n",
       " 774.8092,\n",
       " 786.2595,\n",
       " 786.2595,\n",
       " 786.2595,\n",
       " 793.8931,\n",
       " 759.542,\n",
       " 736.6412,\n",
       " 748.0916,\n",
       " 748.0916,\n",
       " 759.542,\n",
       " 748.0916,\n",
       " 755.7252,\n",
       " 748.0916,\n",
       " 755.7252,\n",
       " 793.8931,\n",
       " 736.6412,\n",
       " 732.8244,\n",
       " 721.374,\n",
       " 748.0916,\n",
       " 721.374,\n",
       " 725.1908000000001,\n",
       " 763.3588,\n",
       " 736.6412,\n",
       " 748.0916,\n",
       " 721.374,\n",
       " 721.374,\n",
       " 736.6412,\n",
       " 763.3588,\n",
       " 732.8244,\n",
       " 736.6412,\n",
       " 751.9084,\n",
       " 751.9084,\n",
       " 744.2748,\n",
       " 759.542,\n",
       " 751.9084,\n",
       " 736.6412,\n",
       " 751.9084,\n",
       " 778.626,\n",
       " 748.0916,\n",
       " 748.0916,\n",
       " 755.7252,\n",
       " 744.2748,\n",
       " 770.9924,\n",
       " 770.9924,\n",
       " 782.4427000000001,\n",
       " 786.2595,\n",
       " 801.5267,\n",
       " 759.542,\n",
       " 767.1756,\n",
       " 790.0763,\n",
       " 751.9084,\n",
       " 770.9924,\n",
       " 774.8092,\n",
       " 778.626,\n",
       " 763.3588,\n",
       " 782.4427000000001,\n",
       " 774.8092,\n",
       " 786.2595,\n",
       " 770.9924,\n",
       " 782.4427000000001,\n",
       " 809.1603,\n",
       " 809.1603,\n",
       " 805.3435,\n",
       " 805.3435,\n",
       " 805.3435,\n",
       " 805.3435,\n",
       " 793.8931,\n",
       " 774.8092,\n",
       " 793.8931,\n",
       " 744.2748,\n",
       " 782.4427000000001,\n",
       " 767.1756,\n",
       " 793.8931,\n",
       " 790.0763,\n",
       " 801.5267,\n",
       " 801.5267,\n",
       " 820.6107,\n",
       " 805.3435,\n",
       " 805.3435,\n",
       " 793.8931,\n",
       " 793.8931,\n",
       " 767.1756,\n",
       " 778.626,\n",
       " 767.1756,\n",
       " 774.8092,\n",
       " 778.626,\n",
       " 782.4427000000001,\n",
       " 755.7252,\n",
       " 786.2595,\n",
       " 786.2595,\n",
       " 790.0763,\n",
       " 759.542,\n",
       " 767.1756,\n",
       " 755.7252,\n",
       " 759.542,\n",
       " 763.3588,\n",
       " 782.4427000000001,\n",
       " 790.0763,\n",
       " 793.8931,\n",
       " 809.1603,\n",
       " 797.7099000000001,\n",
       " 797.7099000000001,\n",
       " 774.8092,\n",
       " 801.5267,\n",
       " 812.9771000000001,\n",
       " 790.0763,\n",
       " 778.626,\n",
       " 782.4427000000001,\n",
       " 786.2595,\n",
       " 805.3435,\n",
       " 770.9924,\n",
       " 793.8931,\n",
       " 793.8931,\n",
       " 770.9924,\n",
       " 786.2595,\n",
       " 809.1603,\n",
       " 793.8931,\n",
       " 774.8092,\n",
       " 812.9771000000001,\n",
       " 816.7939,\n",
       " 809.1603,\n",
       " 812.9771000000001,\n",
       " 820.6107,\n",
       " 809.1603,\n",
       " 809.1603,\n",
       " 801.5267,\n",
       " 812.9771000000001,\n",
       " 824.4275,\n",
       " 828.2443000000001,\n",
       " 797.7099000000001,\n",
       " 805.3435,\n",
       " 797.7099000000001,\n",
       " 809.1603,\n",
       " 805.3435,\n",
       " 801.5267,\n",
       " 816.7939,\n",
       " 801.5267,\n",
       " 828.2443000000001,\n",
       " 847.3282,\n",
       " 839.6947,\n",
       " 832.0611,\n",
       " 824.4275,\n",
       " 816.7939,\n",
       " 805.3435,\n",
       " 835.8779,\n",
       " 824.4275,\n",
       " 832.0611,\n",
       " 832.0611,\n",
       " 839.6947,\n",
       " 820.6107,\n",
       " 851.145,\n",
       " 851.145,\n",
       " 847.3282,\n",
       " 839.6947,\n",
       " 851.145,\n",
       " 854.9618,\n",
       " 870.229,\n",
       " 874.0458,\n",
       " 866.4122,\n",
       " 851.145,\n",
       " 847.3282,\n",
       " 854.9618,\n",
       " 812.9771000000001,\n",
       " 820.6107,\n",
       " 832.0611,\n",
       " 809.1603,\n",
       " 786.2595,\n",
       " 790.0763,\n",
       " 793.8931,\n",
       " 843.5115000000001,\n",
       " 801.5267,\n",
       " 797.7099000000001,\n",
       " 843.5115000000001,\n",
       " 809.1603,\n",
       " 820.6107,\n",
       " 801.5267,\n",
       " 832.0611,\n",
       " 805.3435,\n",
       " 812.9771000000001,\n",
       " 816.7939,\n",
       " 793.8931,\n",
       " 835.8779,\n",
       " 801.5267,\n",
       " 790.0763,\n",
       " 824.4275,\n",
       " 801.5267,\n",
       " 809.1603,\n",
       " 809.1603,\n",
       " 790.0763,\n",
       " 839.6947,\n",
       " 820.6107,\n",
       " 839.6947,\n",
       " 812.9771000000001,\n",
       " 805.3435,\n",
       " 797.7099000000001,\n",
       " 793.8931,\n",
       " 797.7099000000001,\n",
       " 793.8931,\n",
       " 793.8931,\n",
       " 820.6107,\n",
       " 778.626,\n",
       " 816.7939,\n",
       " 797.7099000000001,\n",
       " 793.8931,\n",
       " 790.0763,\n",
       " 790.0763,\n",
       " 812.9771000000001,\n",
       " 790.0763,\n",
       " 801.5267,\n",
       " 774.8092,\n",
       " 812.9771000000001,\n",
       " 782.4427000000001,\n",
       " 774.8092,\n",
       " 816.7939,\n",
       " 797.7099000000001,\n",
       " 770.9924,\n",
       " 778.626,\n",
       " 774.8092,\n",
       " 751.9084,\n",
       " 740.4580000000001,\n",
       " 740.4580000000001,\n",
       " 748.0916,\n",
       " 759.542,\n",
       " 778.626,\n",
       " 748.0916,\n",
       " 751.9084,\n",
       " 725.1908000000001,\n",
       " 748.0916,\n",
       " 744.2748,\n",
       " 744.2748,\n",
       " 732.8244,\n",
       " 744.2748,\n",
       " 709.9237,\n",
       " 709.9237,\n",
       " 713.7405,\n",
       " 740.4580000000001,\n",
       " 740.4580000000001,\n",
       " 736.6412,\n",
       " 755.7252,\n",
       " 748.0916,\n",
       " 736.6412,\n",
       " 732.8244,\n",
       " 767.1756,\n",
       " 751.9084,\n",
       " 751.9084,\n",
       " 759.542,\n",
       " 744.2748,\n",
       " 740.4580000000001,\n",
       " 786.2595,\n",
       " 751.9084,\n",
       " 748.0916,\n",
       " 717.5572999999999,\n",
       " 740.4580000000001,\n",
       " 713.7405,\n",
       " 744.2748,\n",
       " 717.5572999999999,\n",
       " 732.8244,\n",
       " 725.1908000000001,\n",
       " 709.9237,\n",
       " 706.1069,\n",
       " 702.2900999999999,\n",
       " 709.9237,\n",
       " 732.8244,\n",
       " 725.1908000000001,\n",
       " 725.1908000000001,\n",
       " 744.2748,\n",
       " 725.1908000000001,\n",
       " 748.0916,\n",
       " 729.0076,\n",
       " 725.1908000000001,\n",
       " 717.5572999999999,\n",
       " 744.2748,\n",
       " 713.7405,\n",
       " 732.8244,\n",
       " 694.6565,\n",
       " 740.4580000000001,\n",
       " 709.9237,\n",
       " 755.7252,\n",
       " 706.1069,\n",
       " 706.1069,\n",
       " 721.374,\n",
       " 725.1908000000001,\n",
       " 736.6412,\n",
       " 740.4580000000001,\n",
       " 725.1908000000001,\n",
       " 740.4580000000001,\n",
       " 721.374,\n",
       " 751.9084,\n",
       " 744.2748,\n",
       " 717.5572999999999,\n",
       " 713.7405,\n",
       " 732.8244,\n",
       " 751.9084,\n",
       " 767.1756,\n",
       " 755.7252,\n",
       " 725.1908000000001,\n",
       " 782.4427000000001,\n",
       " 759.542,\n",
       " 763.3588,\n",
       " 763.3588,\n",
       " 748.0916,\n",
       " 778.626,\n",
       " 770.9924,\n",
       " 778.626,\n",
       " 770.9924,\n",
       " 763.3588,\n",
       " 809.1603,\n",
       " 767.1756,\n",
       " 786.2595,\n",
       " 778.626,\n",
       " 797.7099000000001,\n",
       " 805.3435,\n",
       " 809.1603,\n",
       " 812.9771000000001,\n",
       " 793.8931,\n",
       " 797.7099000000001,\n",
       " 778.626,\n",
       " 763.3588,\n",
       " 759.542,\n",
       " 786.2595,\n",
       " 782.4427000000001,\n",
       " 770.9924,\n",
       " 767.1756,\n",
       " 763.3588,\n",
       " 770.9924,\n",
       " 778.626,\n",
       " 751.9084,\n",
       " 767.1756,\n",
       " 774.8092,\n",
       " 778.626,\n",
       " 751.9084,\n",
       " 767.1756,\n",
       " 786.2595,\n",
       " 786.2595,\n",
       " 778.626,\n",
       " 786.2595,\n",
       " 770.9924,\n",
       " 767.1756,\n",
       " 755.7252,\n",
       " 767.1756,\n",
       " 748.0916,\n",
       " 797.7099000000001,\n",
       " 744.2748,\n",
       " 748.0916,\n",
       " 748.0916,\n",
       " 732.8244,\n",
       " 732.8244,\n",
       " 736.6412,\n",
       " 736.6412,\n",
       " 751.9084,\n",
       " 755.7252,\n",
       " 755.7252,\n",
       " 755.7252,\n",
       " 748.0916,\n",
       " 774.8092,\n",
       " 751.9084,\n",
       " 767.1756,\n",
       " 774.8092,\n",
       " 740.4580000000001,\n",
       " 755.7252,\n",
       " 770.9924,\n",
       " 751.9084,\n",
       " 793.8931,\n",
       " 767.1756,\n",
       " 729.0076,\n",
       " 767.1756,\n",
       " 763.3588,\n",
       " 751.9084,\n",
       " 770.9924,\n",
       " 744.2748,\n",
       " 763.3588,\n",
       " 744.2748,\n",
       " 759.542,\n",
       " 729.0076,\n",
       " 740.4580000000001,\n",
       " 736.6412,\n",
       " 736.6412,\n",
       " 732.8244,\n",
       " 732.8244,\n",
       " 729.0076,\n",
       " 717.5572999999999,\n",
       " 709.9237,\n",
       " 729.0076,\n",
       " 744.2748,\n",
       " 729.0076,\n",
       " 740.4580000000001,\n",
       " 751.9084,\n",
       " 751.9084,\n",
       " 751.9084,\n",
       " 736.6412,\n",
       " 759.542,\n",
       " 748.0916,\n",
       " 748.0916,\n",
       " 725.1908000000001,\n",
       " 763.3588,\n",
       " 736.6412,\n",
       " 767.1756,\n",
       " 736.6412,\n",
       " 721.374,\n",
       " 748.0916,\n",
       " 774.8092,\n",
       " 748.0916,\n",
       " 729.0076,\n",
       " 759.542,\n",
       " 748.0916,\n",
       " 763.3588,\n",
       " 740.4580000000001,\n",
       " 755.7252,\n",
       " 732.8244,\n",
       " 755.7252,\n",
       " 759.542,\n",
       " 736.6412,\n",
       " 729.0076,\n",
       " 782.4427000000001,\n",
       " 748.0916,\n",
       " 732.8244,\n",
       " 770.9924,\n",
       " 767.1756,\n",
       " 759.542,\n",
       " 778.626,\n",
       " 751.9084,\n",
       " 778.626,\n",
       " 763.3588,\n",
       " 744.2748,\n",
       " 755.7252,\n",
       " 763.3588,\n",
       " 786.2595,\n",
       " 805.3435,\n",
       " 790.0763,\n",
       " 770.9924,\n",
       " 793.8931,\n",
       " 770.9924,\n",
       " 786.2595,\n",
       " 786.2595,\n",
       " 812.9771000000001,\n",
       " 824.4275,\n",
       " 824.4275,\n",
       " 832.0611,\n",
       " 824.4275,\n",
       " 839.6947,\n",
       " 854.9618,\n",
       " 870.229,\n",
       " 858.7786,\n",
       " 858.7786,\n",
       " 866.4122,\n",
       " 885.4962,\n",
       " 885.4962,\n",
       " 877.8626,\n",
       " 912.2137,\n",
       " 877.8626,\n",
       " 885.4962,\n",
       " 908.3969,\n",
       " 904.5802,\n",
       " 912.2137,\n",
       " 927.4809,\n",
       " 938.9313,\n",
       " 942.7481,\n",
       " 946.5649,\n",
       " 946.5649,\n",
       " 954.1985,\n",
       " 908.3969,\n",
       " 931.2977,\n",
       " 931.2977,\n",
       " 980.916,\n",
       " 935.1145,\n",
       " 954.1985,\n",
       " 965.6489,\n",
       " 973.2824,\n",
       " 965.6489,\n",
       " 996.1832,\n",
       " 988.5496,\n",
       " 973.2824,\n",
       " 958.0153,\n",
       " 958.0153,\n",
       " 965.6489,\n",
       " 954.1985,\n",
       " 950.3817,\n",
       " 919.8473,\n",
       " 912.2137,\n",
       " 931.2977,\n",
       " 919.8473,\n",
       " 904.5802,\n",
       " 893.1298,\n",
       " 908.3969,\n",
       " 916.0305,\n",
       " 912.2137,\n",
       " 919.8473,\n",
       " 916.0305,\n",
       " 931.2977,\n",
       " 877.8626,\n",
       " 916.0305,\n",
       " 900.7634,\n",
       " 881.6794,\n",
       " 900.7634,\n",
       " 877.8626,\n",
       " 889.313,\n",
       " 877.8626,\n",
       " 877.8626,\n",
       " 893.1298,\n",
       " 896.9466,\n",
       " 889.313,\n",
       " 893.1298,\n",
       " 900.7634,\n",
       " 877.8626,\n",
       " 866.4122,\n",
       " 877.8626,\n",
       " 881.6794,\n",
       " 851.145,\n",
       " 893.1298,\n",
       " 854.9618,\n",
       " 862.5954,\n",
       " 896.9466,\n",
       " 854.9618,\n",
       " 885.4962,\n",
       " 881.6794,\n",
       " 885.4962,\n",
       " 885.4962,\n",
       " 885.4962,\n",
       " 889.313,\n",
       " 881.6794,\n",
       " 851.145,\n",
       " 847.3282,\n",
       " 877.8626,\n",
       " 835.8779,\n",
       " 839.6947,\n",
       " 824.4275,\n",
       " 828.2443000000001,\n",
       " 862.5954,\n",
       " 843.5115000000001,\n",
       " 843.5115000000001,\n",
       " 839.6947,\n",
       " 832.0611,\n",
       " 797.7099000000001,\n",
       " 812.9771000000001,\n",
       " 832.0611,\n",
       " 812.9771000000001,\n",
       " 816.7939,\n",
       " 832.0611,\n",
       " 809.1603,\n",
       " 793.8931,\n",
       " 816.7939,\n",
       " 793.8931,\n",
       " 835.8779,\n",
       " 786.2595,\n",
       " 801.5267,\n",
       " 782.4427000000001,\n",
       " 797.7099000000001,\n",
       " 793.8931,\n",
       " 790.0763,\n",
       " 797.7099000000001,\n",
       " 797.7099000000001,\n",
       " 790.0763,\n",
       " 782.4427000000001,\n",
       " 770.9924,\n",
       " 770.9924,\n",
       " 770.9924,\n",
       " 770.9924,\n",
       " 774.8092,\n",
       " 767.1756,\n",
       " 801.5267,\n",
       " 786.2595,\n",
       " 751.9084,\n",
       " 748.0916,\n",
       " 744.2748,\n",
       " 740.4580000000001,\n",
       " 740.4580000000001,\n",
       " 736.6412,\n",
       " 763.3588,\n",
       " 740.4580000000001,\n",
       " 751.9084,\n",
       " 736.6412,\n",
       " 751.9084,\n",
       " 732.8244,\n",
       " 751.9084,\n",
       " 751.9084,\n",
       " 732.8244,\n",
       " 736.6412,\n",
       " 759.542,\n",
       " 732.8244,\n",
       " 763.3588,\n",
       " 729.0076,\n",
       " 694.6565,\n",
       " 755.7252,\n",
       " 725.1908000000001,\n",
       " 744.2748,\n",
       " 744.2748,\n",
       " 740.4580000000001,\n",
       " 748.0916,\n",
       " 725.1908000000001,\n",
       " 717.5572999999999,\n",
       " 725.1908000000001,\n",
       " 702.2900999999999,\n",
       " 732.8244,\n",
       " 751.9084,\n",
       " 706.1069,\n",
       " 702.2900999999999,\n",
       " 721.374,\n",
       " 751.9084,\n",
       " 736.6412,\n",
       " 717.5572999999999,\n",
       " 702.2900999999999,\n",
       " 709.9237,\n",
       " 740.4580000000001,\n",
       " 725.1908000000001,\n",
       " 698.4733,\n",
       " 683.2061,\n",
       " 706.1069,\n",
       " 709.9237,\n",
       " 729.0076,\n",
       " 702.2900999999999,\n",
       " 706.1069,\n",
       " 698.4733,\n",
       " 706.1069,\n",
       " 698.4733,\n",
       " 683.2061,\n",
       " 706.1069,\n",
       " 664.1221,\n",
       " 679.3893,\n",
       " 702.2900999999999,\n",
       " 729.0076,\n",
       " 694.6565,\n",
       " 687.0228999999999,\n",
       " 687.0228999999999,\n",
       " 683.2061,\n",
       " 690.8397,\n",
       " 683.2061,\n",
       " 698.4733,\n",
       " 671.7556999999999,\n",
       " 706.1069,\n",
       " 706.1069,\n",
       " 698.4733,\n",
       " 679.3893,\n",
       " 687.0228999999999,\n",
       " 721.374,\n",
       " 717.5572999999999,\n",
       " 702.2900999999999,\n",
       " 721.374,\n",
       " 751.9084,\n",
       " 744.2748,\n",
       " 717.5572999999999,\n",
       " 713.7405,\n",
       " 713.7405,\n",
       " 725.1908000000001,\n",
       " 721.374,\n",
       " 713.7405,\n",
       " 725.1908000000001,\n",
       " 725.1908000000001,\n",
       " 713.7405,\n",
       " 713.7405,\n",
       " 721.374,\n",
       " 729.0076,\n",
       " 706.1069,\n",
       " 713.7405,\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.money_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta =np.array([1]+[2]+[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sta[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = actor.get_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state, reward, done, info = env.step(action)\n",
    "next_state = next_state.astype(np.float32)\n",
    "state =next_state\n",
    "action = actor.get_action(state)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.000000e+00,  2.430000e+02, -1.042200e+00, -1.044731e+02,\n",
       "        2.580940e+01,  3.176570e+05], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state = next_state.astype(np.float32)\n",
    "td_error = critic.learn(state,reward,next_state,done)\n",
    "actor.learn(state,action,td_error)\n",
    "state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state = next_state.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[3.990109]], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_error = critic.learn(state,reward,next_state,done)\n",
    "td_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor.learn(state,action,td_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state =next_state\n",
    "actor.get_action(next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.7747934e-10, 1.0000000e+00, 6.7969017e-09]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_prob = tf.nn.softmax(a).numpy()\n",
    "_prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.rein.choice_action_by_probs(_prob.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-540.5825999999997\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-292.7492\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-394.6581000000001\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-323.8093\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-280.5167999999999\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-441.1003000000003\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-503.5845000000001\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-132.94479999999987\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-368.1445000000001\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-276.1805999999999\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-205.9606\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-298.6876000000002\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-325.9543\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-324.15639999999996\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-314.12779999999987\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n",
      "[1.00000e+00 1.77000e+02 5.20000e-02 8.72270e+00 5.68858e+01 3.12915e+05]\n",
      "For this episode,reward total:-332.0611\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-6a222f2c949a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain_one_episode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-264da1f41a65>\u001b[0m in \u001b[0;36mtrain_one_episode\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mtd_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcritic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtd_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-944fd68766b4>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, state, action, td_error)\u001b[0m\n\u001b[0;32m     22\u001b[0m             _exp_v = tl.rein.cross_entropy_reward_loss(\n\u001b[0;32m     23\u001b[0m                 logits=_logits, actions=[action], rewards=td_error)\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_exp_v\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_AddGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m   (sx, rx, must_reduce_x), (sy, ry, must_reduce_y) = (\n\u001b[1;32m-> 1155\u001b[1;33m       SmartBroadcastGradientArgs(x, y, grad))\n\u001b[0m\u001b[0;32m   1156\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mskip_input_indices\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mskip_input_indices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m     \u001b[0mgx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36mSmartBroadcastGradientArgs\u001b[1;34m(x, y, grad)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0msx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0msy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0mrx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_gradient_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mbroadcast_gradient_args\u001b[1;34m(s0, s1, name)\u001b[0m\n\u001b[0;32m    730\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m    731\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BroadcastGradientArgs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m         tld.op_callbacks, s0, s1)\n\u001b[0m\u001b[0;32m    733\u001b[0m       \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_BroadcastGradientArgsOutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    train_one_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-358.7786"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(env.reward_memory)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
